{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from tensorflow.keras import regularizers, initializers, optimizers, callbacks\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "MAX_NB_WORDS = 20000    # max no. of words for tokenizer\n",
    "MAX_SEQUENCE_LENGTH = 128 # max length of each entry (sentence), including padding\n",
    "VALIDATION_SPLIT = 0.2   # data for validation (not used in training)\n",
    "EMBEDDING_DIM = 50      # embedding dimensions for word vectors (word2vec/GloVe)\n",
    "EMBEDDING_DIM_100 = 100      # embedding dimensions for word vectors (word2vec/GloVe)\n",
    "EMBEDDING_DIM_200 = 200      # embedding dimensions for word vectors (word2vec/GloVe)\n",
    "EMBEDDING_DIM_300 = 300      # embedding dimensions for word vectors (word2vec/GloVe)\n",
    "\n",
    "\n",
    "GLOVE_DIR = \"glove/glove.6B.\"+str(EMBEDDING_DIM)+\"d.txt\"\n",
    "GLOVE_DIR_100 = \"glove/glove.6B.\"+str(EMBEDDING_DIM_100)+\"d.txt\"\n",
    "GLOVE_DIR_200 = \"glove/glove.6B.\"+str(EMBEDDING_DIM_200)+\"d.txt\"\n",
    "GLOVE_DIR_300 = \"glove/glove.6B.\"+str(EMBEDDING_DIM_300)+\"d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>Label</th>\n",
       "      <th>ID</th>\n",
       "      <th>Quote Text</th>\n",
       "      <th>Response Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEN</td>\n",
       "      <td>sarc</td>\n",
       "      <td>GEN_sarc_0000</td>\n",
       "      <td>First off, That's grade A USDA approved Libera...</td>\n",
       "      <td>Therefore you accept that the Republican party...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEN</td>\n",
       "      <td>sarc</td>\n",
       "      <td>GEN_sarc_0001</td>\n",
       "      <td>watch it. Now you're using my lines. Poet has ...</td>\n",
       "      <td>More chattering from the peanut gallery? Haven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEN</td>\n",
       "      <td>sarc</td>\n",
       "      <td>GEN_sarc_0002</td>\n",
       "      <td>Because it will encourage teens to engage in r...</td>\n",
       "      <td>Yep, suppressing natural behavior is always th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEN</td>\n",
       "      <td>sarc</td>\n",
       "      <td>GEN_sarc_0003</td>\n",
       "      <td>Obviously you missed the point. So sorry the t...</td>\n",
       "      <td>I guess we all missed your point Justine, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEN</td>\n",
       "      <td>sarc</td>\n",
       "      <td>GEN_sarc_0004</td>\n",
       "      <td>This is pure paranoia. What evidence do you ha...</td>\n",
       "      <td>Evidence, I dont need no sticking evidence. Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Corpus Label             ID  \\\n",
       "0    GEN  sarc  GEN_sarc_0000   \n",
       "1    GEN  sarc  GEN_sarc_0001   \n",
       "2    GEN  sarc  GEN_sarc_0002   \n",
       "3    GEN  sarc  GEN_sarc_0003   \n",
       "4    GEN  sarc  GEN_sarc_0004   \n",
       "\n",
       "                                          Quote Text  \\\n",
       "0  First off, That's grade A USDA approved Libera...   \n",
       "1  watch it. Now you're using my lines. Poet has ...   \n",
       "2  Because it will encourage teens to engage in r...   \n",
       "3  Obviously you missed the point. So sorry the t...   \n",
       "4  This is pure paranoia. What evidence do you ha...   \n",
       "\n",
       "                                       Response Text  \n",
       "0  Therefore you accept that the Republican party...  \n",
       "1  More chattering from the peanut gallery? Haven...  \n",
       "2  Yep, suppressing natural behavior is always th...  \n",
       "3  I guess we all missed your point Justine, what...  \n",
       "4  Evidence, I dont need no sticking evidence. Th...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/sarcasm_v2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>GEN_sarc_0000</td>\n",
       "      <td>First off, That's grade A USDA approved Libera...</td>\n",
       "      <td>Therefore you accept that the Republican party...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>GEN_sarc_0001</td>\n",
       "      <td>watch it. Now you're using my lines. Poet has ...</td>\n",
       "      <td>More chattering from the peanut gallery? Haven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>GEN_sarc_0002</td>\n",
       "      <td>Because it will encourage teens to engage in r...</td>\n",
       "      <td>Yep, suppressing natural behavior is always th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>GEN_sarc_0003</td>\n",
       "      <td>Obviously you missed the point. So sorry the t...</td>\n",
       "      <td>I guess we all missed your point Justine, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>GEN_sarc_0004</td>\n",
       "      <td>This is pure paranoia. What evidence do you ha...</td>\n",
       "      <td>Evidence, I dont need no sticking evidence. Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Corpus  label             ID  \\\n",
       "0    GEN      1  GEN_sarc_0000   \n",
       "1    GEN      1  GEN_sarc_0001   \n",
       "2    GEN      1  GEN_sarc_0002   \n",
       "3    GEN      1  GEN_sarc_0003   \n",
       "4    GEN      1  GEN_sarc_0004   \n",
       "\n",
       "                                             context  \\\n",
       "0  First off, That's grade A USDA approved Libera...   \n",
       "1  watch it. Now you're using my lines. Poet has ...   \n",
       "2  Because it will encourage teens to engage in r...   \n",
       "3  Obviously you missed the point. So sorry the t...   \n",
       "4  This is pure paranoia. What evidence do you ha...   \n",
       "\n",
       "                                            response  \n",
       "0  Therefore you accept that the Republican party...  \n",
       "1  More chattering from the peanut gallery? Haven...  \n",
       "2  Yep, suppressing natural behavior is always th...  \n",
       "3  I guess we all missed your point Justine, what...  \n",
       "4  Evidence, I dont need no sticking evidence. Th...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning up dataframe columns\n",
    "df = df.rename(columns = {'Quote Text': 'context', 'Response Text': 'response', 'Label': 'label'})\n",
    "df['label'] = df['label'].map({'sarc': 1, 'notsarc': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning text\n",
    "def clean_text(text):\n",
    "    output = \"\"\n",
    "    text = str(text).replace(\"\\n\", \"\")\n",
    "    text = re.sub(r'[^\\w\\s]','',text).lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'clean_context'] = df['context'].apply(clean_text)\n",
    "df.loc[:,'clean_response'] = df['response'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Dataframe Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating the columns of interest\n",
    "context = df[['clean_context', 'label']]\n",
    "\n",
    "#Tokenizing\n",
    "tknzr = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tknzr.fit_on_texts(context['clean_context'])\n",
    "sequences = tknzr.texts_to_sequences(context['clean_context'])\n",
    "context_data = pad_sequences(sequences, padding = 'post', maxlen = MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4692, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19048\n"
     ]
    }
   ],
   "source": [
    "word_index = tknzr.word_index\n",
    "print('Vocabulary size:', len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response Dataframe Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating the columns of interest\n",
    "response = df[['clean_response', 'label']]\n",
    "\n",
    "#Tokenizing\n",
    "tknzr = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tknzr.fit_on_texts(response['clean_response'])\n",
    "sequences = tknzr.texts_to_sequences(response['clean_response'])\n",
    "response_data = pad_sequences(sequences, padding = 'post', maxlen = MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4692, 128)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 16990\n"
     ]
    }
   ],
   "source": [
    "word_index = tknzr.word_index\n",
    "print('Vocabulary size:', len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = int(VALIDATION_SPLIT*context_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = labels[: -num_validation_samples]\n",
    "labels_test = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_train = context_data[: -num_validation_samples]\n",
    "context_test = context_data[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_train = response_data[: -num_validation_samples]\n",
    "response_test = response_data[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe from: glove/glove.6B.100d.txt ..."
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "#f = open(GLOVE_DIR)\n",
    "#print('Loading GloVe from:', GLOVE_DIR,'...', end='')\n",
    "f = open(GLOVE_DIR_100)\n",
    "print('Loading GloVe from:', GLOVE_DIR_100,'...', end='')\n",
    "#f = open(GLOVE_DIR_300)\n",
    "#print('Loading GloVe from:', GLOVE_DIR_300,'...', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      " Proceeding with Embedding Matrix... Completed!\n"
     ]
    }
   ],
   "source": [
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32') \n",
    "f.close()\n",
    "print(\"Done.\\n Proceeding with Embedding Matrix...\", end=\"\")\n",
    "\n",
    "#embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM_100))\n",
    "#embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM_300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(\" Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1212 22:54:31.267709 140456920401728 deprecation.py:506] From /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                           #EMBEDDING_DIM,\n",
    "                           EMBEDDING_DIM_100,\n",
    "                           #EMBEDDING_DIM_300,  \n",
    "                           weights = [embedding_matrix],\n",
    "                           input_length = MAX_SEQUENCE_LENGTH,\n",
    "                           trainable=False,\n",
    "                           name = 'embeddings')\n",
    "embedded_sequences = embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1212 22:54:36.069691 140456920401728 deprecation.py:506] From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1212 22:54:36.192432 140456920401728 deprecation.py:323] From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 128, 100)          2000000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 126, 300)          90300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,128,957\n",
      "Trainable params: 2,128,957\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3003 samples, validate on 751 samples\n",
      "Epoch 1/10\n",
      "3003/3003 [==============================] - 2s 518us/sample - loss: 0.6811 - acc: 0.5638 - val_loss: 0.6501 - val_acc: 0.6245\n",
      "Epoch 2/10\n",
      "3003/3003 [==============================] - 1s 213us/sample - loss: 0.5871 - acc: 0.6900 - val_loss: 0.5836 - val_acc: 0.7031\n",
      "Epoch 3/10\n",
      "3003/3003 [==============================] - 1s 212us/sample - loss: 0.3639 - acc: 0.8435 - val_loss: 0.5902 - val_acc: 0.7470\n",
      "Epoch 4/10\n",
      "3003/3003 [==============================] - 1s 210us/sample - loss: 0.1407 - acc: 0.9540 - val_loss: 0.7465 - val_acc: 0.7270\n",
      "Epoch 5/10\n",
      "3003/3003 [==============================] - 1s 212us/sample - loss: 0.0302 - acc: 0.9937 - val_loss: 0.8861 - val_acc: 0.7270\n",
      "Epoch 6/10\n",
      "3003/3003 [==============================] - 1s 196us/sample - loss: 0.0080 - acc: 0.9997 - val_loss: 0.9854 - val_acc: 0.7337\n",
      "Epoch 7/10\n",
      "3003/3003 [==============================] - 1s 172us/sample - loss: 0.0070 - acc: 0.9987 - val_loss: 1.0408 - val_acc: 0.7257\n",
      "Epoch 8/10\n",
      "3003/3003 [==============================] - 1s 186us/sample - loss: 0.0059 - acc: 0.9993 - val_loss: 1.1017 - val_acc: 0.7310\n",
      "Epoch 9/10\n",
      "3003/3003 [==============================] - 1s 210us/sample - loss: 0.0028 - acc: 0.9997 - val_loss: 1.1745 - val_acc: 0.7230\n",
      "Epoch 10/10\n",
      "3003/3003 [==============================] - 1s 189us/sample - loss: 0.0048 - acc: 0.9997 - val_loss: 1.1684 - val_acc: 0.7350\n",
      "Accuracy: 68.34%\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(MAX_NB_WORDS,\n",
    "                    #EMBEDDING_DIM,\n",
    "                    EMBEDDING_DIM_100,\n",
    "                    #EMBEDDING_DIM_300,\n",
    "                    input_length=MAX_SEQUENCE_LENGTH))\n",
    "                    #input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(300, #128\n",
    "                 3,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "#model.add(Activation('softmax'))\n",
    "\n",
    "#model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "model.fit(response_train, labels_train,\n",
    "          batch_size=32,\n",
    "          #batch_size=20,\n",
    "          #batch_size=10,\n",
    "          #epochs=10,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)\n",
    "          #validation_data=(response_test, labels_test))\n",
    "scores = model.evaluate(response_test, labels_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.round(np.array(model.predict(response_test, batch_size=32)))\n",
    "actualPredictions = []\n",
    "actualLabels = []\n",
    "for i in predictions:\n",
    "    if (i == 1):\n",
    "        actualPredictions.append(1)\n",
    "    else:\n",
    "        actualPredictions.append(0)\n",
    "for i in labels_test:\n",
    "    if (i == 1):\n",
    "        actualLabels.append(1)\n",
    "    else:\n",
    "        actualLabels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp 304\n",
      "tn 337\n",
      "fp 150\n",
      "fn 147\n"
     ]
    }
   ],
   "source": [
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tp = 0\n",
    "numCorrect = 0\n",
    "\n",
    "for i in range(len(actualPredictions)):\n",
    "    if actualPredictions[i] == actualLabels[i]:\n",
    "        if actualPredictions[i] == 0:\n",
    "            tp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "        numCorrect += 1\n",
    "    else:\n",
    "        if actualPredictions[i] == 0:\n",
    "            fn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "print(\"tp \" + str(tp))\n",
    "print(\"tn \" + str(tn))\n",
    "print(\"fp \" + str(fp))\n",
    "print(\"fn \" + str(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.6833688699360341\n"
     ]
    }
   ],
   "source": [
    "print(\"acc: \" + str((1.0*numCorrect)/(len(actualPredictions))))\n",
    "precision = (1.0*tp)/(tp+fp)\n",
    "recall = (1.0*tp)/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67405765 0.32594235]\n",
      " [0.30800821 0.69199179]]\n",
      "precision: 0.6696035242290749\n",
      "recall: 0.6740576496674058\n"
     ]
    }
   ],
   "source": [
    "confusionMatrix = np.zeros((2,2))\n",
    "temp = confusionMatrix[0][0]\n",
    "confusionMatrix[0][0] = recall\n",
    "confusionMatrix[0][1] = 1-recall\n",
    "confusionMatrix[1][1] = float(tn)/(tn+fp)\n",
    "confusionMatrix[1][0] = 1-confusionMatrix[1][1]\n",
    "print(confusionMatrix)\n",
    "print(\"precision: \" + str(precision))\n",
    "print(\"recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(response_train, labels_train, validation_split=0.3, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_t, accuracy_t, f1_score_t, precision_t, recall_t = model.evaluate(response_test, labels_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7396234896645617, 0.6759062, 0.6679221, 0.7117318, 0.6451939)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_t, accuracy_t, f1_score_t, precision_t, recall_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LSTM(300, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "preds = Dense(2, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_r(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_r(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "embeddings (Embedding)       (None, 128, 100)          1699100   \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 128, 300)          481200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               38528     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,235,598\n",
      "Trainable params: 536,498\n",
      "Non-trainable params: 1,699,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import categorical_accuracy\n",
    "model = Model(sequence_input, preds)\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',              \n",
    "             optimizer='adam',\n",
    "             #metrics = ['accuracy'])\n",
    "              metrics = ['accuracy', precision_r, recall_r])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training progress:\n",
      "Train on 3003 samples, validate on 751 samples\n",
      "Epoch 1/3\n",
      "3003/3003 [==============================] - 27s 9ms/sample - loss: 0.4376 - acc: 0.8012 - precision_r: 0.4895 - recall_r: 1.0000 - val_loss: 0.5200 - val_acc: 0.7656 - val_precision_r: 0.5207 - val_recall_r: 1.0000\n",
      "Epoch 2/3\n",
      "3003/3003 [==============================] - 25s 8ms/sample - loss: 0.3598 - acc: 0.8378 - precision_r: 0.4893 - recall_r: 1.0000 - val_loss: 0.5639 - val_acc: 0.7244 - val_precision_r: 0.5207 - val_recall_r: 1.0000\n",
      "Epoch 3/3\n",
      "3003/3003 [==============================] - 25s 8ms/sample - loss: 0.3060 - acc: 0.8645 - precision_r: 0.4894 - recall_r: 1.0000 - val_loss: 0.6584 - val_acc: 0.7284 - val_precision_r: 0.5252 - val_recall_r: 1.0000\n",
      "Accuracy: 70.26%\n"
     ]
    }
   ],
   "source": [
    "print('Training progress:')\n",
    "history = model.fit(response_train, labels_train, epochs = 3, batch_size=32, \n",
    "                    validation_split=0.2)\n",
    "scores = model.evaluate(response_test, labels_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, precision, recall = model.evaluate(response_test, labels_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.70255864, 0.5179167, 1.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, precision, recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
